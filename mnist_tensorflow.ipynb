
from keras.api._v2.keras import activations
import tensorflow as tf
from tensorflow.keras import datasets, layers, models, optimizers
from tensorflow.keras.datasets import mnist

EPOCHS = 10
BATCH_SIZE = 128
VERBOSE = 1
OPTIMIZER = tf.keras.optimizers.Adam()
VALIDATION_SPLIT = .2
IMG_ROWS = 28
IMG_COLS = 28
INPUT_SHAPE = (IMG_ROWS, IMG_COLS,1)
NB_CLASSES = 10

def build(input_shape, classes):
    model = models.Sequential()
    model.add(layers.Convolution2D(32, (3,3), padding = 'same', activation = 'relu', input_shape = input_shape))
    model.add(layers.MaxPooling2D(pool_size= (2,2)))
    model.add(layers.Convolution2D(64, (3,3), padding = 'same', activation = 'relu'))
    model.add(layers.MaxPooling2D(pool_size = (2,2)))
    model.add(layers.Flatten())
    model.add(layers.Dense(50, activation = 'relu'))
    model.add(layers.Dropout(.2))
    model.add(layers.Dense(classes, activation = 'softmax'))
    return model


(x_train, y_train), (x_test, y_test) = mnist.load_data()


x_train = x_train / 255.0
x_test = x_test / 255.0

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train = x_train.reshape((x_train.shape[0], IMG_ROWS, IMG_COLS, 1))
x_test = x_test.reshape((x_test.shape[0], IMG_ROWS, IMG_COLS, 1))

y_train = tf.keras.utils.to_categorical(y_train, NB_CLASSES)
y_test = tf.keras.utils.to_categorical(y_test, NB_CLASSES)




model = build(INPUT_SHAPE, NB_CLASSES)
model.compile(loss = 'categorical_crossentropy', optimizer = OPTIMIZER, metrics = ['accuracy'])

model.summary()

with tf.device('/GPU:0'):
    history = model.fit(x_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS,
                   verbose = VERBOSE, validation_split = VALIDATION_SPLIT)
